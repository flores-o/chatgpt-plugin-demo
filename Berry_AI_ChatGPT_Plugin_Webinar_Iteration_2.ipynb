{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flores-o/chatgpt-plugin-demo/blob/main/Berry_AI_ChatGPT_Plugin_Webinar_Iteration_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwYz2Rwa9RMB",
        "outputId": "07a6e4dd-4659-4f3f-b011-45cc9d226a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.6.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1g-RBkhExWOsNJ17IBOQmv-4owaV5nH1X\n",
            "To: /content/ml_paper.pdf\n",
            "100% 3.26M/3.26M [00:00<00:00, 167MB/s]\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from PyPDF2) (4.5.0)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "#@title # Environment Set-Up\n",
        "!pip install gdown\n",
        "!gdown 1g-RBkhExWOsNJ17IBOQmv-4owaV5nH1X\n",
        "!pip install PyPDF2\n",
        "import json\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Loading our data\n",
        "\n",
        "import PyPDF2\n",
        "pdf_text = \"\"\n",
        "with open(\"./ml_paper.pdf\", \"rb\") as fp:\n",
        "    # Create a PDF object\n",
        "    pdf = PyPDF2.PdfReader(fp)\n",
        "\n",
        "    # Get the number of pages in the PDF document\n",
        "    num_pages = len(pdf.pages)\n",
        "\n",
        "    # Iterate over every page\n",
        "    for page in range(num_pages):\n",
        "        # Extract the text from the page\n",
        "        page_text = pdf.pages[page].extract_text()\n",
        "        pdf_text += page_text"
      ],
      "metadata": {
        "id": "ve3vPeud_P-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_text[:10000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "u5Q3xljpWG0a",
        "outputId": "d5a560eb-9b3c-4672-bbca-c227972f94fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2019 22nd International Conference on Computer and Information Technology (ICCIT), 18 -20 December 2019  \\n978-1-7281 -5842 -6/19/$31.00 ©2019 IEEE   \\nPrognosis and Treatment P rediction  of Type -2 \\nDiabetes U sing Deep  Neural Network and Machine \\nLearning Classifiers   \\nMd. Kowsher  \\nDept. of   Applied Mathematics  \\nNoakhali Science and Technology \\nUniversity, Noakh ali-3814 ,Bangladesh.  \\nga.kowsher@gmail.com  \\n Mahbuba Yesmin Turaba  \\nDept. of Information and \\nCommunication Technology  \\nComilla University  \\nComilla, Bangladesh  \\nmahbuba.yesmin11@gmail.com  \\n \\nM M Mahabubur Rahman  \\nDept. of CSTE  \\nNoakhali Science and Technology \\nUniversity Noakhali -3814, Bangladesh  \\ntoufikrahman098@gmail.com   Tanvir Sajed  \\nDept. of Computing Science  \\nUniversity of Alberta  \\nEdmonton, Canada  \\ntsajed@ualbarta.ca  \\n \\n \\n    Abstract —Type 2 Diabetes is a fast -growing, chronic \\nmetabolic disorder due  to imbalanced insuli n activity. As lots \\nof people are suffering from it, access to proper treatment is \\nnecessary  to control the problem. Most patients are unaware of \\nhealth complexity, symptoms and risk factors before diabetes. \\nThe motion of this research is a comparative stu dy of seven \\nmachine learning classifiers and an artificial neural network \\nmethod to prognosticate the detection and treatment of \\ndiabetes with a high accuracy , in order to identify and treat \\ndiabetes patients at an early age.  Our train ing and test d ataset \\nis an accumulation of 9483 diabetes patients’ information. The \\ntraining dataset is large enough to negate overfitting and \\nprovide for highly accurate test performance. We use \\nperformance measures such as accuracy  and precision to find \\nout the best algorith m deep ANN which outperforms with \\n95.14% accuracy among all  other tested  machine learning \\nclassifiers. We hope our high performing model can be  used by \\nhospitals to predict diabetes and drive research into more \\naccurate prediction models.  \\nKeywords —Artifici al Neural Network,  Type  2 diabetes, Support \\nVector Machine , Decision Tree, Naive Bayes,  LDA,  Random \\nforest classifier  \\nI. INTRODUCTION  \\nDiabetes Mellitus (DM) is a very common metabolic \\ndisorder that affects millions of people worldwide. It occurs \\nwhen the conc entration of blood glucose reaches excessive \\nlevel due to lack of production of insulin by the pancreas \\norgan (Type 1 Diabetes) or due to insulin resistance (Type 2 \\nDiabetes) [1]. It has been published that 422 million people \\nare suffering from diabetes ap proximately in 2014 and it is \\nexpected to rise to 438 million in 2030[2, 3]. Among them, \\n90% of cases are Type 2 diabetes (T2DM) [4]. It may arise \\nat an early childhood because of the failure of cells to \\nrespond to insulin appropriately [5]. So, patients h ave to \\nface excessive tiredness, visual disorders, excessive thirst, \\nskin infection recurrence, delayed wound healing and frequent discharge of urine [6]. It has been pointed out by \\nDiabetes Research Center that 80 percent of cases of \\ndiabetes can be preve nted or delayed if it is detected early \\n[7]. Also, by controlling blood sugar, it is possible to lessen \\nthe T2DM effect. A healthy diet, physical exercise, \\nsufficient nutrition for pregnant women, proper medication, \\nweight at a necessary level are crucial to maintaining a safer \\nsugar level.  \\nWhen the diabetes is diagnosed with medical tests, it \\nshows significantly dangerous symptoms but these methods \\ndo not perform well because of clinical complexity, time -\\nconsuming process and very high expense. However, us ing \\nautomated machine learning algorithms, a researcher can \\npredict a disease like diabetes with reduced cost and time. In \\nthe field of Artificial Intelligence, classification is \\nconsidered a supervised technique that analyses patient data \\nand classifies w hether or not the patient is suffering from a \\ndisease. Researchers have created different AI and machine \\nlearning techniques to automate prognosis of various \\ndiseases. Machine learning techniques studies algorithm and \\nstatistical model that has the capabil ity for accurate \\nprediction by using implicit programming. In medical \\nscience, they take the concept of the human brain as it \\ncontains millions of neurons to complete tasks of the human \\nbody. It is called nonlinear modelling and they are \\ninterconnected lik e brain cells although the neuron c reation \\nis done by program [8].  \\nIn this paper,  first we have discussed various procedures \\nand existing works about the prognosis of T2D , though we \\nemphasized various classification algorithms known as \\nLogistic Regression , KNN, Decision Tree, Naive Bayes, \\nSVM, Linear Discriminant Analysis and Random forest \\nclassifier and Artificial Neural Network (ANN) for T2DM \\nprediction. Our selected model is an Artificial Neural \\nNetwork is found to be superior among all of them . \\nFeedfor ward neural network contains the signal in one \\nAuthorized licensed use limited to: Newcastle University. Downloaded on May 18,2020 at 05:34:25 UTC from IEEE Xplore.  Restrictions apply. direction from the input to the output. It is used in different \\nmedical diagnostic applications such as nephritis disease, \\nheart disease, myeloid leukemia etc. [ref].  \\nWe have taken a medical dataset from Noakh ali Medical  \\nCollege, Bangladesh , consisting  of 9483 samples and 14 \\nsymptoms per sample. The 80% data and  20% data are \\nchosen to be training dataset and testing dataset \\nrespectively. Machine learning classification algorithms are \\napplied to dataset and some  elements may be missed. Then, \\nthe mean and median method is applied in order to detect it.  \\nThe contributions of this paper are summarized as  \\n \\n● We have proposed a  prediction model for T2D \\nusing Artificial Neural Network machine learni ng \\nclassifier  \\n● We have e xerted seven classifier techniques and \\nANN on T2D data and provided comparison of \\naccuracy among them.  \\n● The improvement systems of the model, as well as \\naccuracy, are mentioned in this work.  \\n \\nThe remaining of the discussion is organized as follows: \\nSection -II explains related work of various classification \\ntechniques for prediction of diabetes, Section -III describes \\nthe methodology and materials used, Section -IV discusses \\nevaluated Results and Section -V delineates the conclusion \\nof the research work.  \\n \\nII. RELATE D WORK  \\n \\nIn recent years, several studies have been published using \\nmultiple machine learning classifiers, ANN techniques and \\nvarious feature extraction methods. These have a drastic \\nchange in potential research and some works are discussed \\nrelated to T2DM.  Ebenezer et al. used the backpropagation \\nfeature of ANN in order to diagnose diabetes. It finds out \\nthe error by juxtaposing input and output number. Here, the \\npreceding round error is greater than the present error each \\ntime by means of changing weight t o minimize gradient of \\nerrors using a technique known as gradient descent [9]. \\nNongyao et al. delineated risk prediction by using various \\nmachine learning classification algorithms such as Decision \\nTree, Neural Network, Random Forest algorithms, Naïve \\nBaye s, Logistic Regression. All of them followed Bagging \\nand Boosting approaches to improve robustness except RFA \\n[10].  Deepti et al. proposed a model to identify diabetes at a \\npremature age by applying Decision Tree, SVM and Naïve \\nBayes on Pima Indians Diabe tes Database (PIDD) datasets. \\nThey chose sufficient measures for accuracy including \\nprecision, ROC, F measure, Recall but Naïve Bayes beat \\nthem by acquiring the highest accuracy [11]. Su et al. \\napplied decision tree, logistic regression, neural network,and  \\nrough sets to assess accuracy through various features like \\nage, right thigh circumference, left thigh circumference, \\ntrunk volume and illustrates thigh circumference as a better feature than BMI in anthropometrical data [12]. Al -Rubeaan \\net al. has presen ted T2DM based on diabetic nephropathy \\n(DP), then defined high impact risk factors; age and diabetes \\nduration for microalbuminuria, macroalbuminuria and end -\\nstage renal disease(ESRD) classifications[13]. Vijayan V. \\nexamines various types of preprocessing t echniques which \\nincludes PCA and discretization. It increases the accuracy of \\nNaïve Bayes classifier and Decision Tree algorithm but \\nreduces SVM accuracy [14].  \\nMicheal et al. proposed Multi -Layer Feed Forward \\nNeural Networks (MLFNN) in order to diagnose di abetes by \\nconsidering activation units, learning techniques on Pima \\nIndian Diabetes (PID) data set and achieved 82.5% \\naccuracy. It performs better than Naïve Bayes, Logistic \\nRegression (LR) and Random Forest (RF) classifier [15].  \\nSadri et al. chose data m ining algorithms like Naive Bayes, \\nRBF Network, and J48 to diagnose T2DM for Pima Indians \\nDiabetes Dataset that has 768 samples. Each sample has \\nnine features as the total number of Pregnancy, Plasma \\nGlucose Concentration, Diastolic Blood Pressure and 2 -\\nHour Serum Insulin. Among them, the Naive Bayes \\nalgorithm is unbeatable and has 76.95% accuracy [16]. \\nPradhan et al. devised a classifier for diabetes detection \\nusing Genetic programming (GP) at low cost. Simplified \\nfunction pool consists of arithmetic opera tions that are used \\nin lower validation [17]. Yang Guo et al. applied Naïve \\nBayes classifier by using WEKA tool in order to predict \\nType2 diabetes and obtained remarkable accuracy [18].  \\n \\nUnlike these works, we have introduced diabetes‟s \\nmedication detectio n system using machining learning and \\ndeep ANN that will act like a doctor  to choose the right \\nmedic ation  of a patient suffering from diabetes . \\n \\nIII.MATERIALS AND METHODS  \\n \\nIn order to categorize diabetes therapy and drugs system for \\npatients, the whole wor kflow is separated into four parts \\nsuch as data collection, data preprocessing, training data via \\nthe proposed algorithms, and predictions.  We have exerted \\nseven machine learning classifiers and deep neural networks \\ninto the p'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Experiment 1: Chunking based on sections of the research paper\n",
        "text_list = pdf_text.split(\"I.\")"
      ],
      "metadata": {
        "id": "Qj2Vdhb_BD1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list"
      ],
      "metadata": {
        "id": "r7WlcC2MWVrx",
        "outputId": "a3be9668-4d6d-49e4-aa9f-a20f35763bb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2019 22nd International Conference on Computer and Information Technology (ICCIT), 18 -20 December 2019  \\n978-1-7281 -5842 -6/19/$31.00 ©2019 IEEE   \\nPrognosis and Treatment P rediction  of Type -2 \\nDiabetes U sing Deep  Neural Network and Machine \\nLearning Classifiers   \\nMd. Kowsher  \\nDept. of   Applied Mathematics  \\nNoakhali Science and Technology \\nUniversity, Noakh ali-3814 ,Bangladesh.  \\nga.kowsher@gmail.com  \\n Mahbuba Yesmin Turaba  \\nDept. of Information and \\nCommunication Technology  \\nComilla University  \\nComilla, Bangladesh  \\nmahbuba.yesmin11@gmail.com  \\n \\nM M Mahabubur Rahman  \\nDept. of CSTE  \\nNoakhali Science and Technology \\nUniversity Noakhali -3814, Bangladesh  \\ntoufikrahman098@gmail.com   Tanvir Sajed  \\nDept. of Computing Science  \\nUniversity of Alberta  \\nEdmonton, Canada  \\ntsajed@ualbarta.ca  \\n \\n \\n    Abstract —Type 2 Diabetes is a fast -growing, chronic \\nmetabolic disorder due  to imbalanced insuli n activity. As lots \\nof people are suffering from it, access to proper treatment is \\nnecessary  to control the problem. Most patients are unaware of \\nhealth complexity, symptoms and risk factors before diabetes. \\nThe motion of this research is a comparative stu dy of seven \\nmachine learning classifiers and an artificial neural network \\nmethod to prognosticate the detection and treatment of \\ndiabetes with a high accuracy , in order to identify and treat \\ndiabetes patients at an early age.  Our train ing and test d ataset \\nis an accumulation of 9483 diabetes patients’ information. The \\ntraining dataset is large enough to negate overfitting and \\nprovide for highly accurate test performance. We use \\nperformance measures such as accuracy  and precision to find \\nout the best algorith m deep ANN which outperforms with \\n95.14% accuracy among all  other tested  machine learning \\nclassifiers. We hope our high performing model can be  used by \\nhospitals to predict diabetes and drive research into more \\naccurate prediction models.  \\nKeywords —Artifici al Neural Network,  Type  2 diabetes, Support \\nVector Machine , Decision Tree, Naive Bayes,  LDA,  Random \\nforest classifier  \\n',\n",
              " ' INTRODUCTION  \\nDiabetes Mellitus (DM) is a very common metabolic \\ndisorder that affects millions of people worldwide. It occurs \\nwhen the conc entration of blood glucose reaches excessive \\nlevel due to lack of production of insulin by the pancreas \\norgan (Type 1 Diabetes) or due to insulin resistance (Type 2 \\nDiabetes) [1]. It has been published that 422 million people \\nare suffering from diabetes ap proximately in 2014 and it is \\nexpected to rise to 438 million in 2030[2, 3]. Among them, \\n90% of cases are Type 2 diabetes (T2DM) [4]. It may arise \\nat an early childhood because of the failure of cells to \\nrespond to insulin appropriately [5]. So, patients h ave to \\nface excessive tiredness, visual disorders, excessive thirst, \\nskin infection recurrence, delayed wound healing and frequent discharge of urine [6]. It has been pointed out by \\nDiabetes Research Center that 80 percent of cases of \\ndiabetes can be preve nted or delayed if it is detected early \\n[7]. Also, by controlling blood sugar, it is possible to lessen \\nthe T2DM effect. A healthy diet, physical exercise, \\nsufficient nutrition for pregnant women, proper medication, \\nweight at a necessary level are crucial to maintaining a safer \\nsugar level.  \\nWhen the diabetes is diagnosed with medical tests, it \\nshows significantly dangerous symptoms but these methods \\ndo not perform well because of clinical complexity, time -\\nconsuming process and very high expense. However, us ing \\nautomated machine learning algorithms, a researcher can \\npredict a disease like diabetes with reduced cost and time. In \\nthe field of Artificial Intelligence, classification is \\nconsidered a supervised technique that analyses patient data \\nand classifies w hether or not the patient is suffering from a \\ndisease. Researchers have created different AI and machine \\nlearning techniques to automate prognosis of various \\ndiseases. Machine learning techniques studies algorithm and \\nstatistical model that has the capabil ity for accurate \\nprediction by using implicit programming. In medical \\nscience, they take the concept of the human brain as it \\ncontains millions of neurons to complete tasks of the human \\nbody. It is called nonlinear modelling and they are \\ninterconnected lik e brain cells although the neuron c reation \\nis done by program [8].  \\nIn this paper,  first we have discussed various procedures \\nand existing works about the prognosis of T2D , though we \\nemphasized various classification algorithms known as \\nLogistic Regression , KNN, Decision Tree, Naive Bayes, \\nSVM, Linear Discriminant Analysis and Random forest \\nclassifier and Artificial Neural Network (ANN) for T2DM \\nprediction. Our selected model is an Artificial Neural \\nNetwork is found to be superior among all of them . \\nFeedfor ward neural network contains the signal in one \\nAuthorized licensed use limited to: Newcastle University. Downloaded on May 18,2020 at 05:34:25 UTC from IEEE Xplore.  Restrictions apply. direction from the input to the output. It is used in different \\nmedical diagnostic applications such as nephritis disease, \\nheart disease, myeloid leukemia etc. [ref].  \\nWe have taken a medical dataset from Noakh ali Medical  \\nCollege, Bangladesh , consisting  of 9483 samples and 14 \\nsymptoms per sample. The 80% data and  20% data are \\nchosen to be training dataset and testing dataset \\nrespectively. Machine learning classification algorithms are \\napplied to dataset and some  elements may be missed. Then, \\nthe mean and median method is applied in order to detect it.  \\nThe contributions of this paper are summarized as  \\n \\n● We have proposed a  prediction model for T2D \\nusing Artificial Neural Network machine learni ng \\nclassifier  \\n● We have e xerted seven classifier techniques and \\nANN on T2D data and provided comparison of \\naccuracy among them.  \\n● The improvement systems of the model, as well as \\naccuracy, are mentioned in this work.  \\n \\nThe remaining of the discussion is organized as follows: \\nSection -II explains related work of various classification \\ntechniques for prediction of diabetes, Section -III describes \\nthe methodology and materials used, Section -IV discusses \\nevaluated Results and Section -V delineates the conclusion \\nof the research work.  \\n \\nI',\n",
              " ' RELATE D WORK  \\n \\nIn recent years, several studies have been published using \\nmultiple machine learning classifiers, ANN techniques and \\nvarious feature extraction methods. These have a drastic \\nchange in potential research and some works are discussed \\nrelated to T2DM.  Ebenezer et al. used the backpropagation \\nfeature of ANN in order to diagnose diabetes. It finds out \\nthe error by juxtaposing input and output number. Here, the \\npreceding round error is greater than the present error each \\ntime by means of changing weight t o minimize gradient of \\nerrors using a technique known as gradient descent [9]. \\nNongyao et al. delineated risk prediction by using various \\nmachine learning classification algorithms such as Decision \\nTree, Neural Network, Random Forest algorithms, Naïve \\nBaye s, Logistic Regression. All of them followed Bagging \\nand Boosting approaches to improve robustness except RFA \\n[10].  Deepti et al. proposed a model to identify diabetes at a \\npremature age by applying Decision Tree, SVM and Naïve \\nBayes on Pima Indians Diabe tes Database (PIDD) datasets. \\nThey chose sufficient measures for accuracy including \\nprecision, ROC, F measure, Recall but Naïve Bayes beat \\nthem by acquiring the highest accuracy [11]. Su et al. \\napplied decision tree, logistic regression, neural network,and  \\nrough sets to assess accuracy through various features like \\nage, right thigh circumference, left thigh circumference, \\ntrunk volume and illustrates thigh circumference as a better feature than BMI in anthropometrical data [12]. Al -Rubeaan \\net al. has presen ted T2DM based on diabetic nephropathy \\n(DP), then defined high impact risk factors; age and diabetes \\nduration for microalbuminuria, macroalbuminuria and end -\\nstage renal disease(ESRD) classifications[13]. Vijayan V. \\nexamines various types of preprocessing t echniques which \\nincludes PCA and discretization. It increases the accuracy of \\nNaïve Bayes classifier and Decision Tree algorithm but \\nreduces SVM accuracy [14].  \\nMicheal et al. proposed Multi -Layer Feed Forward \\nNeural Networks (MLFNN) in order to diagnose di abetes by \\nconsidering activation units, learning techniques on Pima \\nIndian Diabetes (PID) data set and achieved 82.5% \\naccuracy. It performs better than Naïve Bayes, Logistic \\nRegression (LR) and Random Forest (RF) classifier [15].  \\nSadri et al. chose data m ining algorithms like Naive Bayes, \\nRBF Network, and J48 to diagnose T2DM for Pima Indians \\nDiabetes Dataset that has 768 samples. Each sample has \\nnine features as the total number of Pregnancy, Plasma \\nGlucose Concentration, Diastolic Blood Pressure and 2 -\\nHour Serum Insulin. Among them, the Naive Bayes \\nalgorithm is unbeatable and has 76.95% accuracy [16]. \\nPradhan et al. devised a classifier for diabetes detection \\nusing Genetic programming (GP) at low cost. Simplified \\nfunction pool consists of arithmetic opera tions that are used \\nin lower validation [17]. Yang Guo et al. applied Naïve \\nBayes classifier by using WEKA tool in order to predict \\nType2 diabetes and obtained remarkable accuracy [18].  \\n \\nUnlike these works, we have introduced diabetes‟s \\nmedication detectio n system using machining learning and \\ndeep ANN that will act like a doctor  to choose the right \\nmedic ation  of a patient suffering from diabetes . \\n \\nII',\n",
              " 'MATERIALS AND METHODS  \\n \\nIn order to categorize diabetes therapy and drugs system for \\npatients, the whole wor kflow is separated into four parts \\nsuch as data collection, data preprocessing, training data via \\nthe proposed algorithms, and predictions.  We have exerted \\nseven machine learning classifiers and deep neural networks \\ninto the pre -processed data set.  \\n \\n \\nFig.1. System  Diagram of T2D analysis  \\nAuthorized licensed use limited to: Newcastle University. Downloaded on May 18,2020 at 05:34:25 UTC from IEEE Xplore.  Restrictions apply. The source of our data came from Noakhali Medical \\nCollege, Bangladesh and the data set is separated into two \\nparts such as training and test set. The training data are \\nmanipulated to the diagnostic system and 13 factors  have \\nbeen taken to determine therapy in order to apply machine \\nlearning and multilayer ANN. The dataset is tested from the \\ntrained machine learning classifiers and artificial neural \\nnetwork.  \\nA. Dataset  \\nAs discussed before our data set contains information  about \\n9483 diabetes patients and formatted in comma -separated -\\nfile (CSV). The dimension of the data set is 9483*14. It \\npreserves 14 different kind of information of a  diabetes \\npatient such as „Name of patient‟,  “Fasting”, “2 h after \\nPressure” “BMI”, “Du ration”, “Age”, “Sex”, “Blood \\npressure”, “High Cholesterols”, “Heart Diseases”, “Kidney \\nDiseases”, and , “Medications”. The first 13 columns are \\nconsidered independent variables and the last one is the \\ndependent variable.  It contains kinds of basic medici ne \\nname of diabetes such as Diet and Lifestyle Modiﬁcation, \\nSecretagogues, Biguanides, and Insulin.  \\nWhen datasets consist of enough variables, it increases the \\naccuracy of prediction. Here, “Fasting” measures blood test \\njust before taking food, “2 h after glucose load” provides a \\nblood test after two hours of eating. “BMI” refers to the \\nweight and height of patients in kg/m2. “Medication” \\nindicates proper drugs and therapy. People who recovered \\nT2DM at early stage follow some features: age group 30 -75 \\nyears , diabetes of diagnosis duration is more than half years, \\nglucose level at fasting plasma is higher than 125 mg/dl, \\ncreation of plasma indicates equal or greater than 1.7 mg/dl, \\nplasma glucose after two hours is 11.  \\nWhen a patient suffers from kidney prob lems, it may be a \\nsymptom of T2DM as higher sugar level may damage \\nnephron. Even bleary eyesight is considered as a side effect \\nfor patients as eye‟s retina and the macula is affected.  Bad \\ncholesterol may lead to Diabetic dyslipidemia which can \\nincrease h eart diseases and atherosclerosis.  Here, we suggest \\ntreatment for kidney and v\\xad\\xad\\xadision problems. In order to \\ncategorize diabetes therapy and drugs system for patients, \\nwe applied seven machine learning classifiers and eight \\ndeep neural into a data system o f Noakhali Medical College, \\nBangladesh. Training data are manipulated to diagnostic \\nsystem and twelve factors have been taken to determine \\ntherapy in order to apply machine learning and multilayer \\nANN. For the training and testing of the systems, we \\ndivide d the data set into 80% training and 20% test set. The \\ntraining dataset is used to find out the appropriate model and \\nbest hyper -parameters and testing data set contains unseen \\ndata to predict the performance.  \\n \\nB. Data preprocessing  \\nData preprocessing invo lves raw data converting into a \\nrecognizable format from various sources. The well -\\npreprocessed data aids for the best training of algorithms. \\nMulti pre -processing training is held in our presented \\nsystems.  1.  Missing Value Check  \\nUsually, missing values may occur due to data \\nincompleteness, missing field, programming error, manual \\ndata transfer from a database and so on. We may ignore \\nmissing values but it causes problems in parameter \\ncalculation and data accuracy for features such as age, \\nwages and fare.  We need to inspect whether a dataset has \\nany missing value or not. There are many ways to handle \\nmissing values such as delete rows, missing values \\nprediction, mean, median, mode and so on. But the most \\nprominent policy for missing value replacement is th e mean \\nmethod and also it is used to exchange the approximate \\nresults in the dataset [19].  Mean is written in this way in \\nmathematics,  \\n                                  (1) \\n \\nWhere, \\n denotes the mean and provides the average number  \\nof n. \\n \\n2. Handling Categorical value  \\nCategorical encoding identifies data type and transfers \\ncategorical features into numerical numbers as the majority \\nof machine learning algorithms could not cope up with label \\ndata directly.  Then numerical values are fed into the \\nspecific model. In our data set, there are five categorical \\nvariable names as „Name of patients‟, “Heart Diseases”, \\n“Kidney Diseases”, “Sex”, and “Medications”. There are \\ntwo popular ways of transforming categorical data into \\nnumerical data su ch as Integer encoding and one -hot \\nencoding.  In the label encoder, categorical features are an \\ninteger value and contain a natural order relationship, but \\nthe multiclass relationship will provide different values for \\nvarious classes. One hot encoding maps  categorical value \\ninto binary vectors. Firstly, it is obvious to assign binary \\nvalue to an integer value of female and male is 0 and 1. \\nThen converting it to a 2 size of 2 possible integers in a \\nbinary vector. Here, a female is encoded as 0 and \\nrepresente d as [1, 0] in which index 0 has value 1 and vice \\nversa. It chooses this value as a feature to influence model \\ntraining [20].  \\n \\n3. Features Selection  \\nFeature selection incorporates the identification and \\nreduction of unnecessary features that have no impac t on the \\nobjective function and high impact features are kept. Our \\ndataset contains 14 types of elements and we have checked \\np-value which is a statistical process for finding out the \\nprobability for the null hypothesis. The features are taken \\nout whose p -value indicates less than 0.05.  \\nMoreover, multicollinearity refers to determine the high \\ncorrelation which exists between two or more independent \\nfeatures and features that are influential to each other. It is \\ncalled redundancy when two features are highl y correlated. \\nAs we have to handle redundancy, it is essential to choose \\nsome methods such as  χ2Test and Correlation Coefficient. \\nAuthorized licensed use limited to: Newcastle University. Downloaded on May 18,2020 at 05:34:25 UTC from IEEE Xplore.  Restrictions apply. The Correlation Coefficient can be calculated by numerical \\ndata. Assume that A and B are two features and it can be \\ndefined as,  \\n \\n             (2)                                                                                              \\n \\nAfter performing both p -value and multicollinearity test, we \\ncould come forward with seven features among thirteen \\nindependent features. Those are “Fasting”, “ 2 Hours after \\nGlucose L oad”  “Duration”, “BMI”, “Hi gh Cholesterols”, \\n“Heart Diseases”, and “Kidney Diseases”.  \\n \\n 4. Feature scaling  \\nMost of the time, the dataset does not remain on the same \\nscale or even not normalized. So, feature scaling is a \\nfundamental data transformation method for coping the \\ndataset to algorithms. We need to scale value of features and \\nprovide equal weight to all features in order to obtain the \\nsame scale for all data. Moreover, it is possible for scaling \\nto change in different values for different features. There are \\nlots of techniqu es for feature scaling for example \\nStandardization, Mean Normalization, Min -Max Scaling, \\nUnit Vector and so on.  \\nIn our research work, we have taken Min -Max Scaling or \\nnormalization process as the features are confined within a \\nbounded area. Minmax normaliz ation is a z -series \\nnormalization to transform linearly x to x‟ where maxX and \\nminX are the maximum and minimum value for X \\nrespectively.  \\n \\n                          (3) \\n \\nWhen x=max, then y =1 and x=min, y=1.  \\n \\nThe scaling range bel ongs between 0 and 1(positive value) \\nand -1 to 1(negative) and we have taken the value between 0 \\nand 1.  \\n \\n5. Dimension Reducing  \\nDimensionality reduction refers to minimizing random \\nvariables by considering the principal set of variables that \\navoids overfitt ing. For a large number of dataset, we need to \\nuse dimension reduction technique. In our study, we prefer \\ndimension reduction for dimensional graphical visualization. \\nThere are a lot of methods for reducing dimension, for \\ninstance, LDA, PCA, SVD, NMF, etc.  In our system, we \\nhave applied Principal Component Analysis (PCA). It is a \\nlinear transformation based on the correlation between \\nfeatures in order to identify patterns. High dimensional data \\nare estimated into equal or lower dimensions through \\nmaximum va riance. We have taken two components of PCA \\naccording to their high variance so that we can graphically \\nvisualize in Cartesian coordinate system.  \\n C. Training Algorithms  \\nThe training dataset for T2DM is applied to each algorithm \\nto find out medications an d model performance is assessed \\nby obtaining accuracy.  \\n \\na. Machine Learning Classifier  \\nSince we focus on the performance of treatment predictions, \\nwe have implemented seven machine learning classifiers \\nsuch as logistic regression, KNN, SVM, Naive Bayes, \\ndecision tree, LDA, random forest tree.   \\nLogistic regression is based on the probability model; it is \\nderived from linear regression that mapped the dataset into \\ntwo categories by considering existing data. At first, features \\nare mapped linearly that are tr ansferred to a sigmoid \\nfunction layer for prediction. It shows the relationship \\nbetween the dependent and independent values but output \\nlimits the prediction range on [0, 1]. As we need to predict \\nthe right treatment of a diabetes person, it is beneficial to \\nuse a binary classification problem.  \\nLinear Discriminant Analysis (LDA) belongs to a linear \\nclassifier to find out the linear correlation between elements \\nin order to support binary and multiclass classification. The \\nchance of inserting a new dataset in to every class is detected \\nby LDA. Then, the class that contains the dataset is detected \\nas output. It can calculate the mean function for each class \\nand it is estimated by vectors for finding group variance.  \\nSupport Vector Machine (SVM) is the most recogn ized \\nclassifier to make decision boundary as hyperplane to keep \\nthe widest distance from both sides of points. This \\nhyperplane refers to separating data into two groups in two -\\ndimensional space. It performs better with non -linear \\nclassification by the kern el function. It is capable of \\nseparating and classifying unsupported data.  \\nK-nearest neighbours (KNN) works instant learning \\nalgorithm and input labeled data that act as training instance. \\nThen, the output produces a group of data. When k=1, 2, 5 \\nthen it means the class has 1, 2 or 5 neighbours of every data \\npoint. For this system, we choose k=5 that means 5 \\nneighbours for every data point. We have taken Minkowski \\ndistance to provide distance between two points in N -\\ndimensional vector space to run data. Su ppose, points p1(x1, \\ny1) and p2(x2, y2) illustrates Minkowski distance as,  \\n                   \\n                   (4) \\nHere, d denotes Minkowski distance  between p1 and p2 \\npoint.  \\n \\nNaive Bayes Classifier is constructed from Bayes theorem, \\nin whic h features are independent of each other in present \\nclass and classification that counts the total number of \\nobservations by calculating the probability to create a \\npredictive model in the fastest time. It outperformed with a \\nhuge dataset of categorical va riables.  The main benefits of \\nthat it involves limited training data to estimate better \\nresults.  Naive Bayes theorem probability can be derived \\nfrom P (T), P(X) and P (X|T). Therefore,  \\n \\n                                    (5) \\nAuthorized licensed use limited to: Newcastle University. Downloaded on May 18,2020 at 05:34:25 UTC from IEEE Xplore.  Restrictions apply. The d ecision tree is a decision -supporting a predictive \\nmodel based on tree structure by putting logic to interpret \\nfeatures. It provides a conditional control system and marks \\nred or green for died or alive leaves. It has three types of \\nnodes: root node, decis ion nodes and leaf nodes. The root \\nnode is the topmost node among them and data are split into \\nchoices to find out the decision‟s result. Decision nodes \\nbasically comprise of decision rules to produce the output \\nby considering all information gain and oval  shape is used to \\ndenote it. The terminal node represents the action that needs \\nto be taken after getting the outcome  of all decisions.  \\n \\nMultiple random trees lead to the random forest to calculate \\nelements of molecular structure. A decision tree looks lik e a \\ntree that is the storehouse of results from the random forest \\nalgorithm and bagging is applied to it in order to reduce \\nbias-variance trade -off. It can perform feature selection \\ndirectly and output represents the mode of all classes. In \\nRandom Forest T ree, we took the total number of trees in \\nthe forest: 10.  \\n \\nb. Artificial Neural Network  \\nAn ANN is considered as a human brain due to consisting \\nmillions of neurons to communicate with each other. It has \\nthree layers; the input layer fed raw data to network , hidden \\nlayer is the middle layer based on input, weight and the \\nrelationship denoted by activity function. Output layers \\nvalue is determined by activity, weight and relationship \\nfrom the second layer.  \\nSince we need to find out the probability of each tre atment \\nand the objective function is not binary, so we used softmax \\nactivation function instead of sigmoid between the hidden \\nlayer and output layer. There is no rule of thumb to choose \\nhidden layer in ANN. If our data is linearly separable then \\nwe don‟t n eed any hidden layer. Then the average node \\nbetween the input and output node is preferable.  \\nIn our system, we prefer six hidden layers between the input \\nnode and the hidden layer and 25 epochs to train a neural \\nnetwork. It has no gradient vanishing probl em and uses \\nReLU activation function to train dataset without \\npretraining.  \\n \\nc. Validation  \\n \\nThe validation is a technique of evaluating the performance \\nof algorithms. It cooperates to evaluate the model and \\nreduce overfitting. Different types of validation method \\nincludes Holdout  method, K -Fold Cross -Validation, \\nStratified K -Fold Cross -Validation and Leave -P-Out Cross -\\nValidation. We have picked out k -fold validation dataset is \\ndivided into k subsets in k times. One k subset act as test set \\nand error is estim ated by average k trails. Therefore, k -1 \\nsubsets produce training set. We prefer k=10 generally \\nwhich contains 10 folds, repeat one time and stratified \\nsampling as each fold has a similar amount of samples.  \\n \\nIV.EXPERIMENTAL RESULT ANALYSIS  \\n A.  Experimental t ool \\nThe whole task has been implemented in python 3.6 \\nprogramming language in Anaconda distribution. Python \\nlibrary offers various facilities to implement machine \\nlearning and deep learning. The unbeatable library for data \\nrepresentation is pandas that pro vide huge commands and \\nlarge data management.  We have used it to read and \\nanalyze data in less writing. Afterward, scikit -learn has \\nfeatures for various classification, clustering algorithms to \\nbuild models. Also, Keras combines the advantages of \\ntheano a nd TensorFlow to train a neural network model. We \\nuse to fit and evaluate function to train and assess neural \\nnetwork model respectively bypassing the same input and \\noutput, then we apply matplotlib for graphical visualization.  \\nB. Model performance  \\nFor boost ing performance, it is always a better idea to \\nincrease data size instead of depending on prediction and \\nweak correlations. Also, adding a hidden layer may increase \\naccuracy and speed due to its tendency to make a training \\ndataset overfit. But partially it  is dependent on the \\ncomplexity of the model. Contrarily, increasing the epochs \\nnumber ameliorate performance though it sometimes \\noverfits training data. It works well for the deep network \\nthan shallow network when considering regulation factor.  \\nHereafter,  we have added another hidden layer; choose \\nepoch 100 then the Deep ANN accuracy risen up to 95.14% \\nwhich is superior among all of them.  \\n \\n \\nFig.2. Models Performance Comparison.  \\nC. Improving Model performance  \\nFor boosting performance, it is always a better i dea to \\nincrease data size instead of depending on prediction and \\nweak correlations. Also, adding a hidden layer may increase \\ntraining accuracy and speed due to its tendency to make \\ntraining dataset overfit. But partially it is dependent on the \\ncomplexity o f the model. Contrarily, increasing the epochs \\nnumber ameliorate performance though it sometimes \\noverfits training data. It works well for the deep network \\nthan shallow network when considering regulation factor.  \\nHereafter, we added another hidden layer; c hoose epoch 100 \\nthen the Deep ANN accuracy of the training and test set is \\nrisen up to 96.42% and 95.14% which is superior among all \\nof them.  \\nAuthorized licensed use limited to: Newcastle University. Downloaded on May 18,2020 at 05:34:25 UTC from IEEE Xplore.  Restrictions apply.  \\nFig.3. 2 -D Graphical Visualization of Test set  \\n \\nD.Final Result  \\nAfter applying feature extraction to the dataset a nd \\nimplementing several types of classification and deep neural \\nnetwork, we found artificial neural network as better \\nperformer with best validity and Random forest classifier \\nare preferable among other machine learning classifiers.  \\n \\n \\nFig.4. Final Result Comparison  \\n \\nV. CONCLUSIONS   \\nType -2 diabetes can lead to a lot of complications as heart \\nattack, kidney damage, blurred vision, hearing problems and \\nAlzheimer‟s disease. The main problem is lower accuracy of \\nthe prediction model, small datasets and inadapta bility to \\nvarious datasets.  In this paper, the medication and treatment \\nare predicted by a comparative study of seven machine \\nlearning algorithms and deep neural networks. Artificial \\nneural networks play a vital role in medical science by \\nminimizing class ification error that leads to greater \\naccuracy.  Experiment result determines the designed ANN \\nsystem  achieved higher accuracy of 94.7%. It can cooperate \\nwith experts to detect T2DM patients at a very early age  and \\nprovide the best treatment option.  \\nIn the  future, we can enhance the accuracy of early \\ntreatment to lessen the suffering of patients. Also, we can \\nimplement more classifiers to pick up the leading one for \\nrecord -breaking performance and extend it to automation \\nanalysis. There is a plan to apply t his designed system in \\ndiabetes or for other diseases. It may increase the performance of prediction of various diseases . Larger \\ndataset leads to the higher training set and it cooperates in \\nadvanced accuracy. It is convenient for people to have an \\napplica tion on their smartphones related to T2DM that may \\nhave T2DM symptoms, treatment, risk factors, and health \\nmanagement.  \\nREFERENCES  \\n \\n[1] https://www.niddk.nih.gov/health -\\ninfor mation/diabetes/overview/what -is-\\ndiabetes?fbclid=IwAR36jKI7GXUE4D0PhZ1Wk4zAa49kKXtn3hB7\\nOqrYSoAqA925MzkXa_1u_Sk [Accessed: 24 June, 2019]  \\n[2] https://www.who.int/health -topics/diabetes [Accessed: 24 June, 2019]  \\n[3] Rawal LB, Tapp RJ, Williams ED, Chan C, Yasin S,  Oldenburg B. \\nPrevention of type 2 diabetes and its complications in developing \\ncountries: a review. Int J Behav Med. 2012; 19:121 –133.  \\n[4] https://www.diabetes.org.uk/diabetes -the-basics/what -is-type-2-\\ndiabetes [Accessed: 24 June, 2019]  \\n[5] https://en.m.wikiped ia.org/wiki/Diabetes?fbclid=IwAR3c20p4V8Np\\nMvAwkTZmEK -rXxnBCZ61jhV87 -ZnfPMNUJDpm9Easq9dDzA \\n[Accessed: 24 June, 2019]  \\n[6] https://idf.org/52 -about -diabetes.html [Accessed: 24 June, 2019]  \\n[7] E. ',\n",
              " ' Mohamed, R. Linde, G. Perriello, N. Di Daniele, S. J. Pöppl and \\nA. De Lorenzo. \"Predicting type 2 diabetes using an electronic nose -\\nbased artificial neural network analysis,\" in Diabetes nutrition & \\nmetabolism Vol.15, No.4, (2002). pp. 222 -215.  \\n[8] R. A. Dunne, Wiley, J., Inc, S. \"A Statistical Approach to Neural \\nNetworks fo r Pattern Recognition\", New Jersey: John Wiley & Sons \\nInc; (2007).  \\n[9] Ebenezer Obaloluwa Olaniyi and Khashman Adnan..“Onset diabetes \\ndiagnosis using artificial neural network”, International Journal of \\nScientific and Engineering research 5.10 (2014).  \\n[10] Nai-Arun, N., Moungmai, R. “Comparison of Classifiers for the Risk \\nof Diabetes Prediction”, Procedia Computer Science vol: 69, pp: 132 –\\n142, 2015.  \\n[11] Deepti Sisodiaa, Dilip Singh Sisodia. “Prediction of Diabetes using \\nClassification Algorithms” International Confer ence on \\nComputational Intelligence and Data Science, 2018  \\n[12] Kowsher, M., Tithi, F. S., Rabeya, T., Afrin, F., & Huda, M. N. \\n(2020). Type 2 Diabetics Treatment and Medication Detection with \\nMachine Learning Classifier Algorithm. In Proceedings of \\nInternation al Joint Conference on Computational Intelligence (pp. \\n519-531). Springer, Singapore.  \\n[13] https://www.ncbi.nlm.nih.gov/pubmed/24586457 [Accessed: 24 June, \\n2019]  \\n[14] Veena Vijayan V. and Anjali C. Decision support systems for \\npredicting diabetes mellitus –a revie w. Proceedings of 2015 global \\nconference on communication technologies (GCCT 2015).  \\n[15] https://www.researchgate.net/publication/331352518_A_Multi -\\nlayer_Feed_Forward_Neural_Network_Approach_for_Diagnosing_D\\niabetes  \\n[16] https://pdfs.semanticscholar.org/ab93/6e4630720cb7f7ead833222b94\\n5dc3801438.pdf  \\n[17] Pradhan, M.A., Rahman, A., Acharya, P., Gawade, R., Pateria, A. \\nDesign of classifier for Detection of Diabetes using Genetic \\nProgramming. In: International Conference on Comput er Science and \\nInformation Technology, Pattaya, Thailand, pp. 125 –130 (2011).  \\n[18] Yang Guo, Karlskrona, S Guohua Bai and Yan Hu. Using Bayes \\nNetwork for Prediction of Type -2 diabetes, IEEE: International \\nConference on Internet Technology And Secured Transacti ons, pp: \\n471 - 472, Dec. 2012.  \\n[19] https://www.analyticsindiamag.com/5 -ways -handle -missing -values -\\nmachine -learning -datasets/  [Accessed: 24 June, 2019]  \\n[20] https://medium.com/@contactsunny/label -encoder -vs-one-hot-\\nencod er- [Accessed: 5 August, 2019]  \\n \\nAuthorized licensed use limited to: Newcastle University. Downloaded on May 18,2020 at 05:34:25 UTC from IEEE Xplore.  Restrictions apply. ']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Creating our doc QA Plugin w/ Berri\n",
        "url = \"https://berriaiapi.krrishdholakia.repl.co/create_app\"\n",
        "data = {\"user_email\": \"krrish@berri.ai\", \"data_source\": json.dumps(text_list)}\n",
        "response = requests.post(url, data=data)\n",
        "response.text"
      ],
      "metadata": {
        "id": "P9gM1_sECDVb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "38757805-8bfb-4b38-d0d9-2d8328705a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"account_email\":\"krrish@berri.ai\",\"api_endpoint\":\"https://api.berri.ai/query?user_email=krrish@berri.ai&instance_id=a3fce912-5113-431a-a104-70002c61874b\",\"instance_id\":\"a3fce912-5113-431a-a104-70002c61874b\",\"playground_endpoint\":\"play.berri.ai/aHR0cHM6Ly9zaGFyZWRkYnN0b3JlcXVlcnktN2JlYS04aGp3LnplZXQtYmVycmkuemVldC5hcHAvYmVycmlfcXVlcnk_cHJval9wYXRoPWluZGV4ZXMva3JyaXNoQGJlcnJpLmFpL2EzZmNlOTEyLTUxMTMtNDMxYS1hMTA0LTcwMDAyYzYxODc0Yg==\",\"plugin_manifest\":\"https://api.berri.ai/a3fce912-5113-431a-a104-70002c61874b/ai-plugin.json\",\"plugin_yaml\":\"https://api.berri.ai/openapi/a3fce912-5113-431a-a104-70002c61874b\",\"website_endpoint\":\"chat.berri.ai/aHR0cHM6Ly9zaGFyZWRkYnN0b3JlcXVlcnktN2JlYS04aGp3LnplZXQtYmVycmkuemVldC5hcHAvYmVycmlfcXVlcnk_cHJval9wYXRoPWluZGV4ZXMva3JyaXNoQGJlcnJpLmFpL2EzZmNlOTEyLTUxMTMtNDMxYS1hMTA0LTcwMDAyYzYxODc0Yg==\"}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Testing our Plugin (ask: what training algorithms were used?)\n",
        "response.json()[\"playground_endpoint\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "PDq_XaJnCD5p",
        "outputId": "15c7234b-d571-4696-93bd-fb0aedc45b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'play.berri.ai/aHR0cHM6Ly9zaGFyZWRkYnN0b3JlcXVlcnktN2JlYS04aGp3LnplZXQtYmVycmkuemVldC5hcHAvYmVycmlfcXVlcnk_cHJval9wYXRoPWluZGV4ZXMva3JyaXNoQGJlcnJpLmFpL2EzZmNlOTEyLTUxMTMtNDMxYS1hMTA0LTcwMDAyYzYxODc0Yg=='"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yiNYuG1rW3Dc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}